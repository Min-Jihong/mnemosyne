# Mnemosyne

한국어 | [English](README.md)

> **당신처럼 생각하는 법을 배우다** - 컴퓨터 행동과 사고 패턴을 학습하는 디지털 트윈

Mnemosyne는 당신의 컴퓨터 상호작용을 기록하고, 각 행동의 **'왜'**를 분석하며, 궁극적으로 당신처럼 생각하고 행동하는 법을 배우는 AI 시스템입니다.

## 개요

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         MNEMOSYNE 아키텍처                               │
│                    "당신처럼 생각하는 법을 배우다"                         │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐              │
│  │   캡처       │───▶│   추론       │───▶│   학습       │              │
│  │   레이어     │    │   레이어     │    │   레이어     │              │
│  └──────────────┘    └──────────────┘    └──────────────┘              │
│         │                   │                   │                       │
│         ▼                   ▼                   ▼                       │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐              │
│  │ 마우스/키보드│    │ LLM 의도     │    │ 행동         │              │
│  │ 화면/오디오  │    │ 추론         │    │ 트랜스포머   │              │
│  └──────────────┘    └──────────────┘    └──────────────┘              │
│                                                 │                       │
│                                                 ▼                       │
│                                          ┌──────────────┐              │
│                                          │   실행       │              │
│                                          │   레이어     │              │
│                                          └──────────────┘              │
└─────────────────────────────────────────────────────────────────────────┘
```

## 주요 기능

### 🎯 마이크로 액션 레코딩
- **마우스 추적**: 이동, 클릭, 더블클릭, 드래그, 스크롤
- **키보드 캡처**: 키 입력, 단축키, 타이핑 패턴
- **화면 캡처**: 액션 발생 시 자동 스크린샷
- **윈도우 컨텍스트**: 활성 앱 및 윈도우 제목 추적

### 🧠 호기심 있는 LLM
수동적인 분석이 아닌, Mnemosyne의 LLM은 능동적으로:
- 당신의 행동 패턴에 대해 **질문**합니다
- 작업 방식의 **패턴을 발견**합니다
- 습관과 선호도에 대한 **인사이트를 생성**합니다

### 💾 영구 메모리 (OpenClaw 스타일)
- 모든 명령과 대화를 기억
- 메모리 시맨틱 검색
- 상위 수준 인사이트를 위한 메모리 통합
- 빠른 검색을 위한 ChromaDB 벡터 저장소

### 🤖 실행 에이전트
- 목표 지향적 컴퓨터 제어
- 속도 제한이 있는 안전 장치
- 보호된 앱 및 단축키
- 신중한 실행을 위한 확인 모드

### 🔌 멀티 프로바이더 LLM 지원
- OpenAI (GPT-4, GPT-4V)
- Anthropic (Claude 3)
- Google (Gemini)
- Ollama (로컬 모델)

## 설치

```bash
# 저장소 클론
git clone https://github.com/yourusername/mnemosyne.git
cd mnemosyne

# pip으로 설치
pip install -e .

# macOS 네이티브 캡처용 (권장)
pip install -e ".[macos]"

# ML 학습 기능용
pip install -e ".[ml]"
```

### macOS 권한

Mnemosyne는 다음 권한이 필요합니다:
- **손쉬운 사용**: 시스템 환경설정 → 보안 및 개인 정보 보호 → 개인 정보 보호 → 손쉬운 사용
- **입력 모니터링**: 시스템 환경설정 → 보안 및 개인 정보 보호 → 개인 정보 보호 → 입력 모니터링
- **화면 기록**: 시스템 환경설정 → 보안 및 개인 정보 보호 → 개인 정보 보호 → 화면 기록

## 빠른 시작

### 1. 설정

```bash
mnemosyne setup
```

대화형 마법사가 다음을 구성합니다:
- LLM 프로바이더 및 API 키
- 모델 선택
- 호기심 모드 설정

### 2. 활동 기록

```bash
# 기록 시작
mnemosyne record --name "내 작업 세션"

# Ctrl+C로 중지
```

### 3. LLM으로 분석

```bash
# 기록된 액션의 의도 추론
mnemosyne analyze <session-id>

# 호기심 있는 LLM이 질문하도록 함
mnemosyne curious <session-id>
```

### 4. 메모리 탐색

```bash
# 메모리 검색
mnemosyne memory "평소 하루를 어떻게 시작하는지"

# 최근 메모리 표시
mnemosyne memory --recent
```

### 5. 목표 실행

```bash
# 학습된 행동을 기반으로 Mnemosyne가 행동하도록 함
mnemosyne execute "평소 아침에 쓰는 앱들 열기"
```

## CLI 명령어

| 명령어 | 설명 |
|--------|------|
| `mnemosyne setup` | 대화형 설정 마법사 |
| `mnemosyne record` | 컴퓨터 활동 기록 시작 |
| `mnemosyne sessions` | 기록된 세션 목록 |
| `mnemosyne analyze <id>` | LLM으로 세션 분석 |
| `mnemosyne curious <id>` | LLM이 탐색하고 질문하도록 함 |
| `mnemosyne memory [query]` | 메모리 검색 또는 탐색 |
| `mnemosyne export <id>` | 학습용 세션 내보내기 |
| `mnemosyne execute <goal>` | 목표 실행 |
| `mnemosyne status` | 설정 표시 |
| `mnemosyne version` | 버전 표시 |

## 설정

설정은 `~/.mnemosyne/config.toml`에 저장됩니다:

```toml
[llm]
provider = "anthropic"  # openai, anthropic, google, ollama
model = "claude-3-opus-20240229"
api_key = "your-api-key"

[curiosity]
mode = "active"  # passive, active, proactive

[recording]
screenshot_quality = 80
screenshot_format = "webp"
mouse_throttle_ms = 50
```

## 프로젝트 구조

```
mnemosyne/
├── capture/      # 입력 기록 (마우스, 키보드, 화면)
├── store/        # SQLite 데이터베이스 및 세션 관리
├── reason/       # LLM 추론 및 호기심 질문
├── memory/       # 벡터 검색이 포함된 영구 메모리
├── learn/        # 학습 파이프라인 및 데이터셋
├── execute/      # 컴퓨터 제어 에이전트
├── llm/          # 멀티 프로바이더 LLM 추상화
├── config/       # 설정 및 구성
└── cli/          # 명령줄 인터페이스
```

## 작동 원리

### 1. 캡처 단계
당신이 수행하는 모든 마이크로 액션이 기록됩니다:
- 마우스 위치, 클릭, 스크롤
- 키보드 입력 및 단축키
- 주요 순간의 스크린샷
- 활성 윈도우 컨텍스트

### 2. 추론 단계
호기심 있는 LLM이 당신의 행동을 분석합니다:
- **"왜 거기를 클릭했나요?"**
- **"타이핑에 어떤 패턴이 있나요?"**
- **"왜 앱 A에서 앱 B로 전환했나요?"**

### 3. 학습 단계
패턴이 추출되고 학습됩니다:
- 액션 시퀀스가 습관이 됩니다
- 의도가 예측 가능해집니다
- 당신의 "디지털 트윈"이 탄생합니다

### 4. 실행 단계
학습된 모델이 행동할 수 있습니다:
- 과거 행동을 기반으로 목표 실행
- 안전 장치가 위험한 행동 방지
- 민감한 작업에 대한 확인

## 안전 기능

Mnemosyne는 여러 안전 메커니즘을 포함합니다:

- **속도 제한**: 기본적으로 분당 최대 60개 액션
- **차단된 앱**: 터미널, 비밀번호 관리자, 시스템 환경설정
- **차단된 단축키**: Cmd+Q, Cmd+Shift+Q 등
- **안전 구역**: 특정 화면 영역으로 액션 제한
- **긴급 정지**: 모든 액션 즉시 중단

## 기여

기여를 환영합니다! PR을 제출하기 전에 기여 가이드라인을 읽어주세요.

## 라이선스

MIT 라이선스 - 자세한 내용은 [LICENSE](LICENSE)를 참조하세요.

## 감사의 글

- 컴퓨터 제어 개념에 영감을 준 [OpenClaw](https://github.com/openclaw)
- 기록 패턴을 위한 [OpenAdapt](https://github.com/OpenAdaptAI/OpenAdapt)
- 입력 모니터링을 위한 [pynput](https://github.com/moses-palmer/pynput)
