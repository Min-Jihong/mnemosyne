# Mnemosyne Architecture

> "Learn to Think Like You" - ë‹¹ì‹ ì˜ ì»´í“¨í„° í–‰ë™ì„ í•™ìŠµí•˜ì—¬ ë‹¹ì‹ ì²˜ëŸ¼ ì‚¬ê³ í•˜ëŠ” ë””ì§€í„¸ íŠ¸ìœˆ

## Overview

MnemosyneëŠ” ì‚¬ìš©ìì˜ ëª¨ë“  ì»´í“¨í„° í–‰ë™ì„ ë§ˆì´í¬ë¡œ ë ˆë²¨ê¹Œì§€ ê¸°ë¡í•˜ê³ , LLMì„ í†µí•´ "ì™œ ì´ í–‰ë™ì„ í–ˆëŠ”ê°€"ë¥¼ ì¶”ë¡ í•˜ì—¬, ê¶ê·¹ì ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì‚¬ê³  íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MNEMOSYNE PIPELINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ CAPTURE  â”‚â”€â”€â–¶â”‚  STORE   â”‚â”€â”€â–¶â”‚  REASON  â”‚â”€â”€â–¶â”‚  LEARN   â”‚â”€â”€â–¶â”‚EXECUTEâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚              â”‚              â”‚              â”‚              â”‚     â”‚
â”‚       â–¼              â–¼              â–¼              â–¼              â–¼     â”‚
â”‚   Mouse/Key      SQLite +       LLM Intent      Action        Computer â”‚
â”‚   Screen/Win     Screenshots    Inference     Transformer      Control â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Principles

1. **Micro-Level Recording**: ë§ˆìš°ìŠ¤ ì¢Œí‘œ, í‚¤ ì…ë ¥, íƒ€ì´ë°ê¹Œì§€ ëª¨ë“  ê²ƒì„ ê¸°ë¡
2. **Context is King**: í–‰ë™ë§Œì´ ì•„ë‹Œ, ê·¸ ìˆœê°„ì˜ í™”ë©´/ìœˆë„ìš°/ì•± ì»¨í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì €ì¥
3. **Intent Inference**: LLMì´ "ì™œ"ë¥¼ ì¶”ë¡ í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜
4. **Behavioral Cloning**: ë‹¨ìˆœ ë§¤í¬ë¡œê°€ ì•„ë‹Œ, ìƒí™©ì— ë§ëŠ” ì ì‘ì  í–‰ë™ í•™ìŠµ
5. **Curious LLM**: LLMì´ ìˆ˜ë™ì ìœ¼ë¡œ ë‹µí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ëŠ¥ë™ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  íŒ¨í„´ì„ íƒìƒ‰
6. **Persistent Memory**: ëª¨ë“  ì‚¬ìš©ì ëª…ë ¹ê³¼ ëŒ€í™”ë¥¼ ì˜êµ¬ ê¸°ì–µí•˜ì—¬ ì¥ê¸°ì  ë§¥ë½ ìœ ì§€

## Phase 1: Capture Layer

### Components

| Module | Purpose | Technology |
|--------|---------|------------|
| `mouse.py` | ë§ˆìš°ìŠ¤ ì´ë™, í´ë¦­, ìŠ¤í¬ë¡¤ ìº¡ì²˜ | pynput |
| `keyboard.py` | í‚¤ ì…ë ¥, ë‹¨ì¶•í‚¤, í…ìŠ¤íŠ¸ íƒ€ì´í•‘ | pynput |
| `screen.py` | ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ (íš¨ìœ¨ì  ì••ì¶•) | Quartz (macOS) |
| `window.py` | í™œì„± ìœˆë„ìš°, ì•± ì •ë³´ | AppKit, Accessibility API |
| `recorder.py` | ì „ì²´ ìº¡ì²˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | asyncio |

### Data Flow

```
User Action
    â”‚
    â”œâ”€â”€â–¶ MouseListener â”€â”€â–¶ MouseEvent(x, y, button, action_type, timestamp)
    â”‚
    â”œâ”€â”€â–¶ KeyboardListener â”€â”€â–¶ KeyEvent(key, modifiers, timestamp)
    â”‚
    â”œâ”€â”€â–¶ ScreenCapture â”€â”€â–¶ Screenshot(image_data, timestamp) [throttled]
    â”‚
    â””â”€â”€â–¶ WindowMonitor â”€â”€â–¶ WindowState(app, title, bounds)
    
    All merged into â”€â”€â–¶ MicroAction(event + context)
```

### Event Types

```python
class ActionType(Enum):
    # Mouse
    MOUSE_MOVE = "mouse_move"
    MOUSE_CLICK = "mouse_click"
    MOUSE_DOUBLE_CLICK = "mouse_double_click"
    MOUSE_RIGHT_CLICK = "mouse_right_click"
    MOUSE_DRAG = "mouse_drag"
    MOUSE_SCROLL = "mouse_scroll"
    
    # Keyboard
    KEY_PRESS = "key_press"
    KEY_RELEASE = "key_release"
    KEY_TYPE = "key_type"      # Aggregated typing
    HOTKEY = "hotkey"          # Cmd+C, Ctrl+V, etc.
```

## Phase 2: Store Layer

### Database Schema

```sql
-- Sessions: ë…¹í™” ì„¸ì…˜
CREATE TABLE sessions (
    id TEXT PRIMARY KEY,
    started_at REAL NOT NULL,
    ended_at REAL,
    description TEXT,
    metadata JSON
);

-- Actions: ê°œë³„ í–‰ë™
CREATE TABLE actions (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL,
    timestamp REAL NOT NULL,
    duration_ms REAL,
    action_type TEXT NOT NULL,
    
    -- Mouse
    mouse_x INTEGER,
    mouse_y INTEGER,
    mouse_dx INTEGER,
    mouse_dy INTEGER,
    mouse_button TEXT,
    
    -- Keyboard
    key_name TEXT,
    key_char TEXT,
    key_code INTEGER,
    modifiers JSON,
    text TEXT,
    
    -- Context
    screenshot_id TEXT,
    window_title TEXT,
    window_bounds JSON,
    active_app TEXT,
    
    -- LLM Inference (filled later)
    inferred_intent TEXT,
    reasoning TEXT,
    
    FOREIGN KEY (session_id) REFERENCES sessions(id),
    FOREIGN KEY (screenshot_id) REFERENCES screenshots(id)
);

-- Screenshots: ìŠ¤í¬ë¦°ìƒ· ë©”íƒ€ë°ì´í„°
CREATE TABLE screenshots (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL,
    timestamp REAL NOT NULL,
    filepath TEXT NOT NULL,
    width INTEGER,
    height INTEGER,
    file_size INTEGER,
    
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
```

### Storage Strategy

- **Screenshots**: WebP í¬ë§· (80% í’ˆì§ˆ), í•„ìš”ì‹œë§Œ ìº¡ì²˜ (ì•¡ì…˜ ë°œìƒ ì‹œ)
- **Actions**: SQLite with WAL mode (ê³ ì† ì“°ê¸°)
- **Compression**: ì„¸ì…˜ ì¢…ë£Œ í›„ ë°°ì¹˜ ì••ì¶•

## Phase 3: Reason Layer

### LLM Intent Inference

ê° í–‰ë™ì— ëŒ€í•´ LLMì´ "ì™œ"ë¥¼ ì¶”ë¡ :

```python
# Input to LLM
{
    "screenshot": <base64 image>,
    "action": {
        "type": "mouse_click",
        "x": 1200, "y": 450,
        "window": "VS Code",
        "element_near_cursor": "Save button"
    },
    "previous_actions": [...last 5 actions...],
    "task_context": "Working on Python project"
}

# LLM Output
{
    "intent": "save_file",
    "reasoning": "User clicked the Save button after making edits to main.py, likely to persist changes before running the code.",
    "confidence": 0.92,
    "semantic_action": "SAVE_CURRENT_FILE"
}
```

### Prompt Strategy (Chain-of-Thought)

```
1. í˜„ì¬ í™”ë©´ ë¶„ì„: ì–´ë–¤ ì•±ì—ì„œ ë¬´ì—‡ì„ ë³´ê³  ìˆëŠ”ê°€?
2. ì´ì „ í–‰ë™ ë¶„ì„: ì§ì „ 5ê°œ í–‰ë™ì˜ ë§¥ë½ì€?
3. í´ë¦­/íƒ€ì´í•‘ ìœ„ì¹˜: ì–´ë–¤ UI ìš”ì†Œì¸ê°€?
4. ì˜ë„ ì¶”ë¡ : ì™œ ì´ í–‰ë™ì„ í–ˆì„ê¹Œ?
5. ì‹œë§¨í‹± ì•¡ì…˜: ê³ ìˆ˜ì¤€ í–‰ë™ìœ¼ë¡œ ë¶„ë¥˜
```

## Phase 4: Learn Layer

### Action Chunking Transformer (ACT)

```
Input: (screenshot, window_state, recent_actions, task_description)
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Vision Encoder                â”‚
â”‚    (ResNet/ViT for screenshot)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Context Encoder                 â”‚
â”‚  (Transformer for action history)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Action Decoder                  â”‚
â”‚  (Predict next K actions as chunk)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
Output: [action_1, action_2, ..., action_K]
```

### Training Data Format

```python
{
    "observation": {
        "screenshot": "path/to/screenshot.webp",
        "window": {"app": "Chrome", "title": "GitHub"},
        "history": [... last 10 actions with intents ...]
    },
    "task": "Create a new repository",
    "action_chunk": [
        {"type": "click", "x": 100, "y": 50, "intent": "click_new_button"},
        {"type": "type", "text": "my-repo", "intent": "enter_repo_name"},
        {"type": "click", "x": 200, "y": 400, "intent": "confirm_creation"}
    ]
}
```

## Phase 5: Execute Layer

### Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENT LOOP                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. Observe: Capture current screen     â”‚
â”‚       â”‚                                 â”‚
â”‚       â–¼                                 â”‚
â”‚  2. Think: Model predicts action chunk  â”‚
â”‚       â”‚                                 â”‚
â”‚       â–¼                                 â”‚
â”‚  3. Act: Execute first action           â”‚
â”‚       â”‚                                 â”‚
â”‚       â–¼                                 â”‚
â”‚  4. Verify: Check if expected result    â”‚
â”‚       â”‚                                 â”‚
â”‚       â””â”€â”€â–¶ Loop until task complete     â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Safety Mechanisms

1. **Allowlist Mode**: íŠ¹ì • ì•±/ì˜ì—­ë§Œ ì œì–´ í—ˆìš©
2. **Confirmation**: ìœ„í—˜ í–‰ë™ (íŒŒì¼ ì‚­ì œ ë“±) ì „ í™•ì¸
3. **Kill Switch**: ì¦‰ì‹œ ì¤‘ë‹¨ ë‹¨ì¶•í‚¤ (Cmd+Shift+Esc)
4. **Sandbox**: ì´ˆê¸°ì—ëŠ” ê°€ìƒ í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰

## Technology Stack

| Layer | Technology | Reason |
|-------|------------|--------|
| Language | Python 3.11+ | ML ìƒíƒœê³„, macOS API ì§€ì› |
| Input Capture | pynput | í¬ë¡œìŠ¤í”Œë«í¼, ì•ˆì •ì  |
| Screen Capture | Quartz (macOS) | ë„¤ì´í‹°ë¸Œ ê³ ì„±ëŠ¥ |
| Database | SQLite | ë‹¨ì¼ íŒŒì¼, ë¹ ë¥¸ ì“°ê¸° |
| Vector Store | ChromaDB | ë¡œì»¬ ì„ë² ë”©, ì‹œë§¨í‹± ê²€ìƒ‰ |
| LLM | Multi-Provider | OpenAI, Anthropic, Google (ì‚¬ìš©ì ì„ íƒ) |
| ML Framework | PyTorch | ACT ëª¨ë¸ êµ¬í˜„ |
| Execution | pyautogui | í¬ë¡œìŠ¤í”Œë«í¼ ìë™í™” |

## LLM Provider System (Multi-Provider Support)

OpenClawì²˜ëŸ¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” LLM í”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•˜ì—¬ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ.

### Supported Providers

| Provider | Models | Vision | Embedding | Setup |
|----------|--------|--------|-----------|-------|
| **OpenAI** | GPT-4o, GPT-4-turbo, GPT-4o-mini | Yes | text-embedding-3-* | API Key |
| **Anthropic** | Claude 3.5 Sonnet, Claude 3 Opus/Haiku | Yes | (via Voyage) | API Key |
| **Google** | Gemini 1.5 Pro, Gemini 1.5 Flash | Yes | text-embedding-004 | API Key |
| **Ollama** | Llama 3, Mistral, etc. | Llava | nomic-embed-text | Local |
| **Custom** | Any OpenAI-compatible API | Varies | Varies | Base URL + Key |

### Configuration Flow (Interactive Setup)

```
$ mnemosyne setup

ğŸ§  Mnemosyne Setup

Step 1/4: LLM Provider
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Choose your LLM provider:
  [1] OpenAI (GPT-4o, GPT-4-turbo)
  [2] Anthropic (Claude 3.5 Sonnet, Claude 3 Opus)
  [3] Google (Gemini 1.5 Pro, Gemini 1.5 Flash)
  [4] Ollama (Local - Llama 3, Mistral)
  [5] Custom (OpenAI-compatible API)

> 2

Step 2/4: API Key
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Enter your Anthropic API key:
> sk-ant-xxxxx

Verifying... âœ“ Valid

Step 3/4: Model Selection
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Choose your primary model:
  [1] claude-3-5-sonnet-20241022 (Recommended - Best balance)
  [2] claude-3-opus-20240229 (Most capable)
  [3] claude-3-haiku-20240307 (Fastest, cheapest)

> 1

Step 4/4: Embedding Provider
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Choose embedding provider for memory search:
  [1] OpenAI (text-embedding-3-small) - Requires OpenAI key
  [2] Voyage AI (voyage-3) - Optimized for Claude
  [3] Local (nomic-embed-text via Ollama) - No API needed
  [4] Same as LLM provider (if supported)

> 3

âœ… Setup complete! Configuration saved to ~/.mnemosyne/config.toml
```

### Configuration File (~/.mnemosyne/config.toml)

```toml
[llm]
provider = "anthropic"
model = "claude-3-5-sonnet-20241022"
api_key_env = "ANTHROPIC_API_KEY"  # Reference to env var
# api_key = "sk-ant-xxx"  # Or direct (not recommended)

# Vision model (for screenshot analysis)
[llm.vision]
provider = "anthropic"  # Can be different from main
model = "claude-3-5-sonnet-20241022"

# Lightweight model for simple tasks
[llm.fast]
provider = "anthropic"
model = "claude-3-haiku-20240307"

[embedding]
provider = "ollama"
model = "nomic-embed-text"
# base_url = "http://localhost:11434"  # For Ollama

# Alternative: OpenAI embeddings
# [embedding]
# provider = "openai"
# model = "text-embedding-3-small"
# api_key_env = "OPENAI_API_KEY"

[memory]
db_path = "~/.mnemosyne/memory.db"
vector_db_path = "~/.mnemosyne/chroma"
consolidation_interval = "daily"  # When to run memory consolidation

[capture]
screenshot_quality = 80
screenshot_format = "webp"
excluded_apps = ["1Password", "Keychain Access", "Banking App"]

[curiosity]
mode = "curious"  # passive, curious, interactive, proactive
```

### Provider Interface (Unified API)

```python
from abc import ABC, abstractmethod
from typing import AsyncIterator

class LLMProvider(ABC):
    """Base class for all LLM providers."""
    
    @abstractmethod
    async def complete(
        self,
        messages: list[Message],
        model: str | None = None,
        **kwargs
    ) -> Response:
        """Generate a completion."""
        pass
    
    @abstractmethod
    async def complete_with_vision(
        self,
        messages: list[Message],
        images: list[bytes],
        model: str | None = None,
        **kwargs
    ) -> Response:
        """Generate completion with image understanding."""
        pass
    
    @abstractmethod
    async def stream(
        self,
        messages: list[Message],
        **kwargs
    ) -> AsyncIterator[str]:
        """Stream completion tokens."""
        pass


class EmbeddingProvider(ABC):
    """Base class for embedding providers."""
    
    @abstractmethod
    async def embed(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings for texts."""
        pass
    
    @abstractmethod
    def dimension(self) -> int:
        """Return embedding dimension."""
        pass
```

### Provider Implementations

```python
# mnemosyne/llm/providers/anthropic.py
class AnthropicProvider(LLMProvider):
    def __init__(self, api_key: str):
        self.client = anthropic.AsyncAnthropic(api_key=api_key)
    
    async def complete_with_vision(self, messages, images, model=None, **kwargs):
        # Convert images to base64 for Claude
        image_content = [
            {"type": "image", "source": {"type": "base64", "data": b64encode(img)}}
            for img in images
        ]
        # ... implementation

# mnemosyne/llm/providers/openai.py
class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str, base_url: str | None = None):
        self.client = openai.AsyncOpenAI(api_key=api_key, base_url=base_url)
    
    # ... implementation

# mnemosyne/llm/providers/google.py
class GoogleProvider(LLMProvider):
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
    
    # ... implementation

# mnemosyne/llm/providers/ollama.py
class OllamaProvider(LLMProvider):
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
    
    # ... implementation (no API key needed)
```

### Factory Pattern for Provider Creation

```python
# mnemosyne/llm/factory.py
from mnemosyne.config import Config

def create_llm_provider(config: Config) -> LLMProvider:
    """Create LLM provider based on config."""
    provider_type = config.llm.provider
    
    match provider_type:
        case "openai":
            return OpenAIProvider(
                api_key=config.get_api_key("openai"),
                base_url=config.llm.get("base_url")
            )
        case "anthropic":
            return AnthropicProvider(
                api_key=config.get_api_key("anthropic")
            )
        case "google":
            return GoogleProvider(
                api_key=config.get_api_key("google")
            )
        case "ollama":
            return OllamaProvider(
                base_url=config.llm.get("base_url", "http://localhost:11434")
            )
        case _:
            raise ValueError(f"Unknown provider: {provider_type}")

def create_embedding_provider(config: Config) -> EmbeddingProvider:
    """Create embedding provider based on config."""
    # Similar pattern
    ...
```

### Environment Variables Support

```bash
# .env or shell exports
export ANTHROPIC_API_KEY="sk-ant-xxx"
export OPENAI_API_KEY="sk-xxx"
export GOOGLE_API_KEY="xxx"

# Config references these:
# api_key_env = "ANTHROPIC_API_KEY"
```

### Runtime Provider Switching

```python
# Can switch providers at runtime for different tasks
async def analyze_screenshot(screenshot: bytes) -> str:
    # Use vision-capable model
    provider = get_provider("vision")
    return await provider.complete_with_vision(
        messages=[{"role": "user", "content": "What's happening in this screenshot?"}],
        images=[screenshot]
    )

async def quick_classification(text: str) -> str:
    # Use fast model for simple tasks
    provider = get_provider("fast")
    return await provider.complete(
        messages=[{"role": "user", "content": f"Classify: {text}"}]
    )
```

## Data Privacy & Security

- **Local First**: ëª¨ë“  ë°ì´í„°ëŠ” ë¡œì»¬ì—ë§Œ ì €ì¥
- **Encryption**: ë¯¼ê° ë°ì´í„° (ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ ë“±) ìë™ ë§ˆìŠ¤í‚¹
- **Opt-out Apps**: íŠ¹ì • ì•± (ì€í–‰, ë¹„ë°€ë²ˆí˜¸ ê´€ë¦¬ì) ë…¹í™” ì œì™¸
- **Data Retention**: ì„¤ì • ê°€ëŠ¥í•œ ìë™ ì‚­ì œ ì£¼ê¸°

## Phase 6: Memory Layer (Persistent Memory)

OpenClawì²˜ëŸ¼ ëª¨ë“  ì‚¬ìš©ì ëª…ë ¹ê³¼ ëŒ€í™”ë¥¼ ì˜êµ¬ ê¸°ì–µí•˜ëŠ” ì‹œìŠ¤í…œ.

### Memory Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MEMORY SYSTEM                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Episodic   â”‚   â”‚  Semantic   â”‚   â”‚ Procedural  â”‚                   â”‚
â”‚  â”‚   Memory    â”‚   â”‚   Memory    â”‚   â”‚   Memory    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚        â”‚                 â”‚                 â”‚                            â”‚
â”‚        â–¼                 â–¼                 â–¼                            â”‚
â”‚   ê°œë³„ ì´ë²¤íŠ¸         ì¶”ì¶œëœ ì§€ì‹       í•™ìŠµëœ íŒ¨í„´                      â”‚
â”‚   (ëª…ë ¹, ëŒ€í™”)       (ì‚¬ì‹¤, ì„ í˜¸ë„)     (í–‰ë™ ì‹œí€€ìŠ¤)                    â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Vector Store (Embeddings)                      â”‚  â”‚
â”‚  â”‚              ChromaDB / Qdrant (Semantic Search)                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Types

| Type | ì €ì¥ ë‚´ìš© | ê²€ìƒ‰ ë°©ì‹ | ì˜ˆì‹œ |
|------|----------|----------|------|
| **Episodic** | êµ¬ì²´ì  ì´ë²¤íŠ¸, ëª…ë ¹, ëŒ€í™” | ì‹œê°„ìˆœ + ì‹œë§¨í‹± | "ì–´ì œ GitHubì—ì„œ ë­˜ í–ˆì§€?" |
| **Semantic** | ì¶”ì¶œëœ ì‚¬ì‹¤, ì„ í˜¸ë„, ì§€ì‹ | ì‹œë§¨í‹± ê²€ìƒ‰ | "ë‚´ê°€ ì„ í˜¸í•˜ëŠ” ì½”ë”© ìŠ¤íƒ€ì¼ì€?" |
| **Procedural** | ë°˜ë³µëœ í–‰ë™ íŒ¨í„´, ì›Œí¬í”Œë¡œìš° | ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ | "PR ì˜¬ë¦´ ë•Œ í•­ìƒ í•˜ëŠ” ìˆœì„œ" |

### Database Schema (Memory)

```sql
-- Episodic Memory: ëª¨ë“  ëª…ë ¹ê³¼ ëŒ€í™”
CREATE TABLE episodic_memory (
    id TEXT PRIMARY KEY,
    timestamp REAL NOT NULL,
    type TEXT NOT NULL,  -- 'command', 'conversation', 'observation'
    content TEXT NOT NULL,
    context JSON,  -- ë‹¹ì‹œ ìƒí™© (ì•±, ì‘ì—… ë“±)
    embedding BLOB,  -- Vector embedding for semantic search
    importance REAL DEFAULT 0.5,  -- ì¤‘ìš”ë„ (0-1)
    access_count INTEGER DEFAULT 0,
    last_accessed REAL
);

-- Semantic Memory: ì¶”ì¶œëœ ì§€ì‹
CREATE TABLE semantic_memory (
    id TEXT PRIMARY KEY,
    category TEXT NOT NULL,  -- 'preference', 'fact', 'skill', 'relationship'
    subject TEXT NOT NULL,
    predicate TEXT NOT NULL,
    object TEXT NOT NULL,
    confidence REAL DEFAULT 0.5,
    source_episodes JSON,  -- ì´ ì§€ì‹ì´ ì¶”ì¶œëœ ì—í”¼ì†Œë“œë“¤
    created_at REAL NOT NULL,
    updated_at REAL NOT NULL,
    embedding BLOB
);

-- Procedural Memory: í–‰ë™ íŒ¨í„´
CREATE TABLE procedural_memory (
    id TEXT PRIMARY KEY,
    name TEXT,  -- íŒ¨í„´ ì´ë¦„ (ìë™ ë˜ëŠ” ì‚¬ìš©ì ì§€ì •)
    trigger_context JSON,  -- ì´ íŒ¨í„´ì´ í™œì„±í™”ë˜ëŠ” ì¡°ê±´
    action_sequence JSON,  -- í–‰ë™ ì‹œí€€ìŠ¤
    frequency INTEGER DEFAULT 1,
    success_rate REAL DEFAULT 1.0,
    last_used REAL,
    embedding BLOB
);
```

### Memory Operations

```python
class MemorySystem:
    async def remember(self, event: MemoryEvent) -> str:
        """ìƒˆë¡œìš´ ì´ë²¤íŠ¸ë¥¼ ê¸°ì–µ"""
        
    async def recall(self, query: str, limit: int = 10) -> List[Memory]:
        """ê´€ë ¨ ê¸°ì–µ ê²€ìƒ‰ (ì‹œë§¨í‹± + ì‹œê°„ ê°€ì¤‘ì¹˜)"""
        
    async def consolidate(self) -> None:
        """ì—í”¼ì†Œë“œ â†’ ì‹œë§¨í‹± ë©”ëª¨ë¦¬ ë³€í™˜ (ìˆ˜ë©´ ì¤‘ ê¸°ì–µ ì •ë¦¬ì²˜ëŸ¼)"""
        
    async def forget(self, criteria: ForgetCriteria) -> int:
        """ì¤‘ìš”ë„ ë‚®ì€ ê¸°ì–µ ì •ë¦¬ (ì„ íƒì )"""
        
    async def extract_knowledge(self, episodes: List[Episode]) -> List[SemanticFact]:
        """ì—í”¼ì†Œë“œì—ì„œ ì‹œë§¨í‹± ì§€ì‹ ì¶”ì¶œ"""
```

### Memory Consolidation (ê¸°ì–µ ì •ë¦¬)

ì£¼ê¸°ì ìœ¼ë¡œ ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œë§¨í‹±/í”„ë¡œì‹œì €ëŸ´ ë©”ëª¨ë¦¬ë¡œ ë³€í™˜:

```python
# ì˜ˆ: ë°˜ë³µ íŒ¨í„´ ê°ì§€
episodes = await memory.get_recent(hours=24)
patterns = await llm.analyze_patterns(episodes)

# "ì‚¬ìš©ìëŠ” í•­ìƒ ì»¤ë°‹ ì „ì— í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•œë‹¤"
await memory.store_semantic(
    category="preference",
    subject="user",
    predicate="always_does_before_commit",
    object="run_tests",
    confidence=0.85
)
```

## Phase 7: Curious LLM (ëŠ¥ë™ì  íƒêµ¬)

LLMì´ ìˆ˜ë™ì ìœ¼ë¡œ "ì™œ?"ì—ë§Œ ë‹µí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ëŠ¥ë™ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  íƒêµ¬í•˜ëŠ” ì‹œìŠ¤í…œ.

### Curiosity Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CURIOUS LLM ENGINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚ Pattern Detectorâ”‚â”€â”€â–¶ "ì´ í–‰ë™ì´ í‰ì†Œì™€ ë‹¤ë¥´ë„¤?"                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                             â”‚
â”‚           â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚Question Generatorâ”‚â”€â”€â–¶ "ì™œ ì˜¤ëŠ˜ì€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í–ˆì„ê¹Œ?"              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                             â”‚
â”‚           â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚Hypothesis Engineâ”‚â”€â”€â–¶ "ì•„ë§ˆ ìƒˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í…ŒìŠ¤íŠ¸ ì¤‘ì¸ ê²ƒ ê°™ë‹¤"      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                             â”‚
â”‚           â–¼                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚ Verification   â”‚â”€â”€â–¶ ê°€ì„¤ ê²€ì¦ (ì¶”ê°€ ê´€ì°° or ì‚¬ìš©ì ì§ˆë¬¸)             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Curiosity Triggers

| Trigger | ì„¤ëª… | LLM ì§ˆë¬¸ ì˜ˆì‹œ |
|---------|------|--------------|
| **Anomaly** | í‰ì†Œ íŒ¨í„´ê³¼ ë‹¤ë¥¸ í–‰ë™ | "ë³´í†µ Cmd+Së¡œ ì €ì¥í•˜ëŠ”ë°, ì™œ ë©”ë‰´ë¥¼ í´ë¦­í–ˆì§€?" |
| **New Pattern** | ì²˜ìŒ ë³´ëŠ” í–‰ë™ ì‹œí€€ìŠ¤ | "ì´ ì•±ì€ ì²˜ìŒ ì“°ëŠ” ê²ƒ ê°™ì€ë°, ë­í•˜ëŠ” ì•±ì´ì§€?" |
| **Inefficiency** | ë¹„íš¨ìœ¨ì  ë°˜ë³µ | "ê°™ì€ ì‘ì—…ì„ 3ë²ˆ ë°˜ë³µí–ˆëŠ”ë°, ìë™í™”í•  ìˆ˜ ìˆì„ê¹Œ?" |
| **Gap** | ì´í•´ ëª»í•œ ë¶€ë¶„ | "ì™œ ê°‘ìê¸° í„°ë¯¸ë„ì„ ì—´ì—ˆì§€? ë§¥ë½ì´ ì•ˆ ë³´ì¸ë‹¤" |
| **Contradiction** | ì´ì „ íŒ¨í„´ê³¼ ëª¨ìˆœ | "í‰ì†Œì—” í…ŒìŠ¤íŠ¸ ë¨¼ì € í•˜ëŠ”ë°, ì™œ ì˜¤ëŠ˜ì€ ë°”ë¡œ ì»¤ë°‹?" |

### Curiosity Modes

```python
class CuriosityMode(Enum):
    PASSIVE = "passive"      # ê´€ì°°ë§Œ, ì§ˆë¬¸ ì•ˆ í•¨
    CURIOUS = "curious"      # ë‚´ë¶€ì ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±, ì‚¬ìš©ìì—ê²Œ ë¬»ì§€ ì•ŠìŒ
    INTERACTIVE = "interactive"  # ê¶ê¸ˆí•˜ë©´ ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì§ˆë¬¸
    PROACTIVE = "proactive"  # ì ê·¹ì ìœ¼ë¡œ ì œì•ˆ ("ì´ê±° ìë™í™”í• ê¹Œìš”?")
```

### Curiosity Questions Storage

```sql
CREATE TABLE curiosity_log (
    id TEXT PRIMARY KEY,
    timestamp REAL NOT NULL,
    trigger_type TEXT NOT NULL,  -- anomaly, new_pattern, etc.
    trigger_context JSON,  -- íŠ¸ë¦¬ê±°ëœ ìƒí™©
    question TEXT NOT NULL,  -- ìƒì„±ëœ ì§ˆë¬¸
    hypothesis TEXT,  -- LLMì˜ ê°€ì„¤
    resolution TEXT,  -- í•´ê²° (answered, inferred, asked_user)
    answer TEXT,  -- ë‹µë³€ (ìˆì„ ê²½ìš°)
    learned_fact TEXT  -- ì´ë¡œë¶€í„° í•™ìŠµí•œ ê²ƒ
);
```

### Interactive Curiosity Flow

```python
# ì´ìƒ í–‰ë™ ê°ì§€ ì‹œ
if curiosity_mode == CuriosityMode.INTERACTIVE:
    question = await llm.generate_question(anomaly)
    
    # ì ì ˆí•œ íƒ€ì´ë°ì— ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ (ì‘ì—… ì¤‘ë‹¨ ìµœì†Œí™”)
    if user_seems_idle():
        answer = await ask_user(question)
        await memory.store_qa(question, answer)
    else:
        # ë‚˜ì¤‘ì— ë¬¼ì–´ë³´ê¸° ìœ„í•´ íì— ì €ì¥
        await curiosity_queue.add(question)
```

### Learning from Curiosity

í˜¸ê¸°ì‹¬ â†’ ì§ˆë¬¸ â†’ ë‹µë³€ â†’ ì§€ì‹ ì¶”ì¶œ ì‚¬ì´í´:

```
1. ê´€ì°°: ì‚¬ìš©ìê°€ VS Codeì—ì„œ Vim ëª¨ë“œë¥¼ ì¼°ë‹¤
2. ì§ˆë¬¸: "ì™œ ê°‘ìê¸° Vim ëª¨ë“œë¥¼ ì“°ê¸° ì‹œì‘í–ˆì§€?"
3. ê°€ì„¤: "ìƒì‚°ì„± í–¥ìƒì„ ìœ„í•´ ìƒˆ ë„êµ¬ë¥¼ ë°°ìš°ëŠ” ì¤‘ì¼ ìˆ˜ë„"
4. (Interactive ëª¨ë“œ) ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸
5. ë‹µë³€: "íŒ€ì—ì„œ Vim ì“°ëŠ” ì‚¬ëŒì´ ë§ì•„ì„œ ë°°ì›Œë³´ë ¤ê³ "
6. í•™ìŠµ: semantic_memoryì— ì €ì¥
   - subject: "user"
   - predicate: "is_learning"
   - object: "vim_for_team_collaboration"
```

## Updated Pipeline (with Memory + Curiosity)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MNEMOSYNE FULL PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚CAPTURE â”‚â”€â–¶â”‚ STORE  â”‚â”€â–¶â”‚ REASON â”‚â”€â–¶â”‚ LEARN  â”‚â”€â–¶â”‚EXECUTE â”‚â”€â–¶â”‚FEEDBACKâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚           â”‚           â”‚           â”‚           â”‚           â”‚         â”‚
â”‚       â”‚           â”‚           â”‚           â”‚           â”‚           â”‚         â”‚
â”‚       â”‚           â–¼           â–¼           â”‚           â”‚           â”‚         â”‚
â”‚       â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚           â”‚           â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â–¶â”‚      MEMORY         â”‚â—€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚              â”‚  (Episodic/Semantic/â”‚                                        â”‚
â”‚              â”‚    Procedural)      â”‚                                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                        â”‚                                                    â”‚
â”‚                        â–¼                                                    â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚              â”‚   CURIOUS LLM       â”‚                                        â”‚
â”‚              â”‚  (Questions/Hypo/   â”‚                                        â”‚
â”‚              â”‚   Verification)     â”‚                                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Future Enhancements

1. **Multi-modal Input**: ìŒì„± ëª…ë ¹, ì œìŠ¤ì²˜ ì¸ì‹
2. **Collaborative Learning**: ì—¬ëŸ¬ ì‚¬ìš©ì íŒ¨í„´ í†µí•© (opt-in)
3. **Real-time Coaching**: ì‘ì—… ì¤‘ íŒíŠ¸ ì œê³µ
4. **Cross-device Sync**: ì—¬ëŸ¬ ê¸°ê¸° ê°„ í•™ìŠµ ë°ì´í„° ë™ê¸°í™”
5. **Dream Mode**: ìˆ˜ë©´/ìœ íœ´ ì‹œê°„ì— ê¸°ì–µ ì •ë¦¬ ë° íŒ¨í„´ ìµœì í™”
6. **Personality Evolution**: ì‹œê°„ì´ ì§€ë‚˜ë©° ì‚¬ìš©ì ì„±í–¥ì— ë§ê²Œ LLM ì„±ê²© ì¡°ì •
