# Mnemosyne Social Media Templates

Ready-to-use templates for promoting Mnemosyne on social media platforms.

---

## Twitter/X Thread

### Tweet 1 (Hook)
```
üßµ I built an open-source "digital twin" that learns to think like you.

Unlike screen recorders that capture pixels, this AI asks "Why did you do that?" after EVERY action.

Here's how Mnemosyne works:
```

### Tweet 2
```
1/ Most screen recorders capture PIXELS.
Mnemosyne captures INTENT.

After every click, keystroke, or app switch, the AI asks: "Why?"

Over time, it builds a model of YOUR thought patterns.
```

### Tweet 3
```
2/ It records EVERYTHING at microsecond precision:
‚Ä¢ Mouse clicks & trajectories
‚Ä¢ Keyboard inputs & hotkeys
‚Ä¢ App switches & window focus
‚Ä¢ Screenshots at key moments

All stored LOCALLY. Privacy-first. üîí
```

### Tweet 4
```
3/ The "Curious LLM" finds patterns YOU didn't notice:

"You typed 'git status' 47 times but only committed 5x.
That's a 9:1 check-to-commit ratio.
Anxiety or process?"

ü§Ø AI-powered self-reflection
```

### Tweet 5
```
4/ OCR Search: Find ANYTHING you've ever seen on screen

"That API key from last week's Slack message"
‚Üí Instantly searchable

Never lose track of what you saw again.
```

### Tweet 6
```
5/ Action Replay: Time-travel through your sessions

See what you did, when, and WHY (AI-inferred intent)

Perfect for:
‚Ä¢ Debugging your workflow
‚Ä¢ Finding lost information
‚Ä¢ Understanding your habits
```

### Tweet 7
```
6/ Multi-LLM support:
‚Ä¢ OpenAI GPT-4
‚Ä¢ Anthropic Claude 3
‚Ä¢ Google Gemini
‚Ä¢ Local Ollama models

Use the AI you trust. Run completely offline if you want.
```

### Tweet 8
```
7/ Coming soon:
üéØ Goal execution (your digital twin acts for you)
üìä Habit tracking with AI insights
üîÑ Cross-device sync

The future: A digital clone that truly thinks like you.
```

### Tweet 9 (CTA)
```
‚≠ê Star on GitHub: github.com/Min-Jihong/mnemosyne

Open source (MIT). Python 3.11+.
macOS first, Linux coming.

Contributions welcome!

#AI #LLM #Python #OpenSource #Productivity #DigitalTwin
```

---

## LinkedIn Post

```markdown
üß† Excited to share Mnemosyne - an open-source AI that creates a digital clone by learning how you think.

**The Problem:**
Traditional automation records WHAT you do, but not WHY. Scripts break in new situations because they don't understand intent.

**The Solution:**
Mnemosyne records every micro-action (clicks, keystrokes, app switches) and has a "Curious AI" that continuously asks "Why did you do this?" to understand your thought patterns.

**Key Features:**
üìπ Micro-action recording with millisecond precision
ü§î AI that asks questions to understand your intent
üìä Daily summaries: "You typed 'git status' 47 times but committed 5x"
üîç OCR search: Find text from any screenshot
‚è™ Action replay: See what, when, and WHY you did it
üîí Privacy-first: All data stored locally

**Tech Stack:**
‚Ä¢ Python 3.11+ with async-first architecture
‚Ä¢ Multi-LLM: OpenAI, Anthropic, Google, Ollama
‚Ä¢ ChromaDB for semantic memory
‚Ä¢ FastAPI web interface

**I'm looking for:**
‚Ä¢ Early adopters to provide feedback
‚Ä¢ Contributors (Python, ML, React)
‚Ä¢ Ideas for new use cases

GitHub: https://github.com/Min-Jihong/mnemosyne

If you've ever wished you had a digital version of yourself, check it out!

#AI #MachineLearning #OpenSource #Productivity #Python #DigitalTwin
```

---

## Reddit Post (r/Python, r/MachineLearning)

### Title
```
[P] Mnemosyne: Open-source digital twin that learns your thought patterns from computer behavior
```

### Body
```markdown
Hey everyone! I've been working on Mnemosyne, an open-source project that creates a digital clone by learning from your computer behavior.

**The Problem:**
Traditional automation tools record *what* you do, but not *why*. They replay fixed scripts that break in new situations.

**The Solution:**
Mnemosyne records every micro-action (clicks, keystrokes, app switches) and has a "Curious AI" that asks "Why did you do this?" to understand your intent.

**What makes it different:**
- ü§î **Intent inference**: AI asks "Why?" after every action
- üìä **Daily AI summaries**: "You typed 'git status' 47 times but only committed 5x"
- üîç **OCR search**: Find text from any screenshot you've taken
- ‚è™ **Action replay**: See what you did, when, and *why*
- üîí **Privacy-first**: Local storage, PII scrubbing, your choice of LLM
- üîå **Multi-LLM**: OpenAI, Anthropic, Google, or local Ollama

**Tech stack:**
- Python 3.11+, async-first architecture
- FastAPI web interface
- ChromaDB for semantic memory
- pyobjc for macOS native capture

**GitHub**: https://github.com/Min-Jihong/mnemosyne

Looking for:
- Feedback from early adopters
- Contributors (especially for Windows/Linux support)
- Ideas for new features

Any questions or suggestions welcome!
```

---

## Hacker News Submission

### Title (80 chars max)
```
Show HN: Mnemosyne ‚Äì Open-source digital twin that learns how you think
```

### Text
```
Hi HN! I built Mnemosyne, an open-source tool that creates a digital clone of yourself by learning from your computer behavior.

Unlike screen recorders that capture pixels, Mnemosyne's AI asks "Why did you do that?" after every action and builds a model of your thought patterns.

**Key features:**
‚Ä¢ Micro-action recording (mouse clicks, keystrokes, app switches)
‚Ä¢ Curious AI that infers intent ("Why did you switch apps 47 times?")
‚Ä¢ OCR search: Find anything you've seen on screen
‚Ä¢ Action replay: Time-travel through sessions with AI-inferred intent
‚Ä¢ Privacy-first: PII scrubbing, local storage
‚Ä¢ Multi-LLM: OpenAI, Anthropic, Google, or local Ollama

**Use cases:**
- Understand your productivity patterns
- Search for "that thing I saw last week"
- Build a digital twin that can act on your behalf

**Tech:** Python 3.11+, FastAPI, ChromaDB, multi-provider LLM abstraction

GitHub: https://github.com/Min-Jihong/mnemosyne

Would love feedback and contributions! Especially interested in:
- Windows/Linux capture support
- Additional LLM integrations
- ML training pipeline improvements
```

---

## Dev.to / Medium Article Outline

### Title
```
Building a Digital Twin That Learns How You Think: The Journey of Mnemosyne
```

### Outline
1. **Introduction** (Hook with the dream of "another me")
2. **The Problem** (Why existing tools fall short)
3. **The Solution** (Curious AI + Intent inference)
4. **Technical Deep Dive**
   - Micro-action capture architecture
   - LLM provider abstraction
   - ChromaDB for semantic memory
5. **Demo** (GIFs/screenshots of key features)
6. **Challenges & Learnings**
   - Privacy considerations
   - Performance optimization
   - Multi-platform support
7. **Roadmap** (Future features)
8. **Call to Action** (Star, contribute, feedback)

---

## Product Hunt Launch

### Tagline
```
Create another you ‚Äî AI that learns how you think
```

### Description
```
Mnemosyne is your digital twin that learns by watching you work.

Unlike screen recorders that capture pixels, Mnemosyne's AI asks "Why?" after every action to understand your thought patterns.

‚ú® Features:
‚Ä¢ Record every micro-action (clicks, keystrokes, switches)
‚Ä¢ AI-powered intent inference
‚Ä¢ OCR search across all screenshots
‚Ä¢ Time-travel replay with AI insights
‚Ä¢ Privacy-first design
‚Ä¢ Works with GPT-4, Claude, Gemini, or local models

Perfect for:
‚Üí Productivity analysis
‚Üí Workflow optimization  
‚Üí Building your digital clone
```

### Topics
`Productivity`, `Artificial Intelligence`, `Open Source`, `Developer Tools`, `macOS`

---

## YouTube/Demo Video Script

### Structure (2-3 minutes)
1. **Hook** (0:00-0:15): "What if you could clone your thought patterns?"
2. **Problem** (0:15-0:30): Screen recorders capture actions, not intent
3. **Solution** (0:30-0:45): Introducing Mnemosyne
4. **Demo** (0:45-2:00):
   - Recording a session
   - AI asking curious questions
   - OCR search
   - Action replay
   - Daily summary
5. **Tech** (2:00-2:30): Multi-LLM, privacy features
6. **CTA** (2:30-3:00): GitHub link, star request

---

## Quick Social Copy

### One-liner
```
üß† Mnemosyne: Open-source AI that learns to think like you by recording your behavior and asking "Why?"
```

### With emoji
```
üß† Digital twin that learns how you think
üìπ Records every micro-action
ü§î AI asks "Why did you do that?"
üîç OCR search your past
‚è™ Replay sessions with intent
üîí Privacy-first

GitHub: github.com/Min-Jihong/mnemosyne
```

### Hashtags
```
#AI #LLM #Python #OpenSource #Productivity #DigitalTwin #MachineLearning #Automation #SelfImprovement
```
